Learn how to turn text into speech. In this episode of Azure tips and tricks, you can use the Azure neural text to speech service to turn text into human speech in many languages and voices. Let's create a small app to use the service to follow along. You need the latest version of visual Studio and you can also do the same in visual studio code. I'll start by creating a text to speech service in Azure here. Let's search for speech. OK? There it is create, this creates a cognitive service, speech service which includes a P end points like the text to speech service. Let's start by giving it a name next, I'll pick a location also a pricing tier. OK? And now select a resource group that's it, create it and I'll skip to when it is done here. It is. This is the cognitive services speech service. Let's take a look at the keys and endpoints blade. OK. We need this information for our application. We need the access key and also the location. So West Europe, in my case. All right, let's use the service in an app. This is visual studio and I've already created a simple console application. The first thing that I changed was to add a new get package. Let's take a look. I added this one for the cognitive services speech service. OK. Let's go back to the program dot CS. In here, I've added a using for the cognitive services speech name space. And here I create a new config with the access key and location that we saw in the

portal. Next, I use this config to create a speech synthesizer and finally, I invoke speak text, a sync with a text that I want to be turned into speech. Let's try this out and there it goes synthesizing directly to speaker output. See the audio comes directly from the default audio device. Cool. These are the default settings which means that the service detects the language of the text and uses the default voice to synthesize it. It uses us English for this. You can change these defaults for instance by inserting this, this configures the speech service to use British English. Instead, let's see synthesizing directly to speaker output. Yep, that works. You can use multiple voices for a language so I can change this to use another voice. Let's try this one synthesizing directly to speaker output. See that sounds very different, very cool. Also by default, the audio is returned through the default audio output of your device. You can change this to return the audio into a memory stream or into a file like this, this outputs the audio into a file called audio dot wave and you can tweak the parameters of the audio that goes into that file as well. The Azure neural text to speech service enables you to convert text to lifeline speech which is close to human parity, go and check it out.