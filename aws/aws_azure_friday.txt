Hey friends for over 30 years. Banks, governments manufacturers and other industries have relied on Microsoft integration technology such as host integration server to access and work with data on their midrange and mainframe systems. Now you can add Azure logic apps to your list of options for solving your mission critical integration needs. Harold Campos is here to show me how it works today on Azure Friday. Hey friends. I'm Scott Hanselman and it's Azure Friday. Today, I'm chatting with Harold Compos. Who's gonna talk to me about cloud native capabilities, integrating with mainframe and mid ranges. How are you, sir? I'm good. I'm good. How are you, Scott? All good. I am. You're, you're scratching a neuron in my brain that I haven't thought about in many, many years. I did a lot of mainframe work at both Nike and a bunch of banks. I did a ton of integration work throughout the nineties and during uh the Y2K uh stuff working in banks. So this is very exciting that we're still keeping these mainframes chugging and bringing them to the cloud. Yes, it is. It is Scott and mainframes are still around and we have to work with them as part of the mission critical scenarios for our customers. Yeah, I understand that a huge amount of people are putting their data on mainframes. They're still out there. Mainframes exist. They're not old in legacy. They are fundamental to so many businesses. So when the world moved to the cloud mainframes came for the ride, you are correct. So let me, let me show you a little bit about the evolution of the mainframes over over the last 70 years. So mainframes, they started around 1950 they've been evolving the hardware and the networking has been evolving um from what you used to have, you know, back in the day to what what you have today. Um But basically at its core mainframes remain the same. So on the inside the applications, they are left mostly untouched, which poses the challenges because there is a lot of data and a lot of mission critical systems being hosted in, in in those devices. Despite their modernization, it is estimated that there are trillions of dollars that were invested back in the day in SNASN A applications which was the the the predecessor of TCP\/IP, right? That applications were linked to the way how protocols work as you know. So then um they are still around and, and they represent uh they represent a um how can I say this one of these situations that customers, they have to deal with this on a daily basis mission critical customers like

banks. As you said now, what we've been working on over the last few years is that we've been in, do you remember host integration servers? But oh my goodness, host integration server, I wanna say 93 94 we would use that to talk to all kinds of big iron. So well, we still have host integration server. We support the product, we have it. The core version is host integration server 2020. But what we've been doing over the last five years is we've been introducing these core technologies of integration that host integration server has to logic apps. So now the majority of the capabilities that you have in your logic apps in host integration server, they are now available in logic apps via logic apps connectors. There is um there is there's been efforts to uh uh to support our customers in the mainframe modernization space. Um There are different approaches for mainframe modernization. There is lift and shift code conversion, um extension of capabilities and and rewriting uh this uh mainframe systems. And on top of this, what there are other patterns and we've been learning from customers that customers are really pursuing or they are asking for help on managing the dependencies because it's not just about migrating the mainframe, it's not just about migrating the application but what happens? What is with what is left behind on premises, right? You still have to deal with those systems or how is it that you interact with what you modernize to the cloud? So for those scenarios is where we have logic apps and host integration server, host integration server capabilities that allow customers to continue using these legacy assets in the in what is left from the mainstream or the dependencies from the mainstream that has been migrated to the cloud to to assure and, and, and I think I think something that is worth mentioning is that if we see this from a cloud perspective, we have a workflow, a logic apps workflow, which which has a different type, different types of connectors that allow integration with different types of systems on premises in the cloud making a hybrid architecture. But we also have all of these connectors, these legacy integration connectors, mainframe and new integration connectors like IBM MQ, host files, 30,270 to interact with between screens CICS systems, DV, two databases, IMS a transaction manager and IMS a database which is a hierarchical database. So if, if you see the word from a um from a cloud perspective uh and, and the enablement to bring the cloud and additional scenarios with software that allows to enable and empower all of these scenarios that today we have like for instance, dealing with terminals or printers or ATM S every time that you go to an ATM, you are likely using a host integration server and to, to interact with the main um and also the capabilities that uh that you can gain if you continue modernizing this workload with any of our partners. So then logic apps becomes the uh the the product for, for for integration for legacy like main flips and news ranges. And and let me show you, yeah, go ahead if I may 1 thing I want to comment on is that with Azure logic apps, you know, you have these wonderful LEGO blocks and you know, I like to think about it in the modern world. There's like blob storage and http and you can go and do these things and you, you then start in other things like service, bus and file systems, all of those pieces that uh Azure provides are available to you in a workflow. Why shouldn't your big iron be available to you as well? I should be able to call a mainframe and put something in storage and make an HTTP call and they're all peers in that wonderful logic apps workflow. And it sounds like that's what you're making possible. Absolutely. Absolutely. And on top of HDP, you know, I think, I think what sometimes is, is a bit of a challenge to explain to, to, to, to, to folks is that a mainframe is not only a server, right? A mainframe is really an ecosystem, you know, you host applications, you host data, you host messaging systems, right? So then um integrating with them, um it's, it's, it's, it's is and then they, they have to see holistically, right? From different angles and different protocols and different uh uh approaches and patterns and technologies. So let me show you a little bit of what we have today with uh with um as we ups and our mainframe and mid ranges connectors. Yeah, let's do it. Let me let me open the the portal. OK. So in the portal, um I go to my logic app, I have a logic app that is called on your Friday here, right? One important aspect to mention is that to set up this app to, to to have the vnet integration capability enabled because you definitely want your mainframe uh not to

be exposed. So you, you want to use a vnet, a virtual network to to to interact with your mainframe and then um open the right ports and, and, and to make sure that you have access to the right facilities in the mainframe, this workflow that I have here um consolidates all of our connectors. It has all of the connectors that we have available for mainframes and we have the let me go this amount. So this is a fairly difficult work flow and uh it has the ability to integrate with using 30,270 which is a protocol that was created to work with the screens, the screens that you are very familiar with the D two connector that uses a T CPA P connectivity to get into ad two database host files, offline connector, which is a connector that has a parser that of binary files. And we'll see how it works. We have a connector for IMS systems. IMS is one of the oldest systems around. It was built for the Apollo mission back in 1966 you have the C IC connector for a system system, the C I system who was born in 1968 and you have also an M two connector. So then all of these connectors, they are available with logic apps. So then now with logic apps, you can integrate all of these different different types of systems from our workflow. And and, and to be honest, I think, I think this is something that the team has been working very hard and, and, and we are so happy with the outcome because in the end, it allows a two mission critical integration with these legacy systems. A couple of things to add before, before running this short demo is that for some of the connectors that you have that I just presented, you have to create a definition that is based in what we call copybook, copybook files, which are basically a representation of the Cobalt programs that represent the parameters of each one of the of these legacy programs. For instance, for C I CS, we require one for I MS, we require another another type, right? For a data structure, we require another um another structure which we available. Uh We uh in visual studio, we can create a mirror of this structure using visual studio. Um And uh in a in a file that we call hid course integration definition XML file, but basically represents, you know, your, your, your binary file, your binary structure, your co copybook in the in the mainframe. So then once you have to find all of these, so then the other thing that you have to have available is access to the system. So as I said, you have to enable the right protocols and you have to be able to, to integrate with uh with this system via the core protocols, either HT or snap whatever is being used by uh by, by your system. Uh Now let me go back to the demo. Then what what is going to happen is that I'm going to upload a file which is a binary file from, from my machine. I will brow for the file. And this is a data set that I created that um typically is generated by uh in, in, in the mainframe, right? And then what is going to happen is that this workflow, we read uh the binary date of this file and we pass it to, to some of these connectors and then it will trigger some of these activities in this workflow if I go to overview uh and then, then I go to uh uh run history. We'll see that this workflow is running here. Then I'm going to repeat the detail of the workflow to see how is it doing. And then, and then we see something, something very important here, right? So this has been completed, the call out to the IMS program took 0.2 seconds and this is a call from the cloud. So it went to the, it went from, from the Loic app to the mainframe. It did some data extraction, it executed a metal and it returned the value of 777.12 right? Which is what basically the outcome of the mainframe program. This thing happened with the system. I have another problem that does the same, it returns the same amount. And also I was able to send a cue to this MQ system that recites the mainframe and I send it. And then I have the body, the response of this data that I that I sent and a couple of things to add is that uh the, the, the data that I sent was binary and then it was successfully parsed by this parser, right? If you see the outcome here, you see that this is the data and this is the data that I wanted to, to show you in here. Just, just give me one second, you see that um it's so cool to see the terminal, I haven't thought about these in a long time, but the the reminder that they're out there and that they're, they're producing and holding such important data. Yes, it is. It is. It is. And, and um let me, let me show you something real quick. It's just uh um it's just taking some time. So I'll um I'll go to my data set, this one that I exported and I'm going to process right. And then you will see that it has two records. So these two records that I had

on the file as the two records that have been passed, that data that you saw was binary data. And that binary data was basically um parts by this host connection. And just to finish. So we are executing a and we are getting this is a select from a table on the same and we are executing for 32 70 navigation plan, which is basically what we call a of a screen, a set of a screen that have a sequence. And for you to get to a particular result, you have to create a navigation that mimics all of the sequence of these screens using a tool that is called the 3270 tool or three DT. With this tool, you are able to create a sequence of screens. And once you have to find the screens, then this plan will take you to the actual results. And this is fantastic for robotic process automation scenarios. And that is what happened So that's the reason why it took longer because you have to do computation in the cloud and on the mainframe. And that's what I want to show you. This is basically, you know, to summarize some of the capabilities that we have today in logic apps to integrate with these legacy systems. There's so many different connectors, there's so many ways to talk to so many different databases over so many different protocols. Like you said, it's really a on ramp into an ecosystem and what's so important about this. And what I think we want people to understand is that once you get it into logic apps, once you get it into Azure, then you can join the other ecosystem, which is the Azure Ecosystem, data lakes and data, um you know, logging management uh analysis, all of that work. Once you can bring those two ecosystems together with logic apps and integration server as the bridge, you can really do some cool solutions very quickly. Exactly, exactly. You're spot on Scott and, and, and the fact that this is the result of work that was uh conducted by a team for the last 30 years. I think it's because this is not new technology, right? I mean the work that we've done and that we have running on this mission critical customers for so long uh speak, speak because the customers they are still using integration, right? Very cool. Yeah, those core capabilities that have been around that have been reliable and been used in a host integration server. Now brought to logic apps. It's peanut butter and chocolate together. My two favorite things. Very cool. Thank you so much Harold Compos for showing me about this uh this new stuff. Thank you. Thank you. Thank you. All right. I am learning all about Azure logic apps, bringing those cloud native capabilities to integrate our mainframes and our mid ranges today on Azure Friday. Hey, thanks for watching this episode of Azure Friday. Now, I need you to like it, comment on it, tell your friends retweet it, watch more Azure Friday.