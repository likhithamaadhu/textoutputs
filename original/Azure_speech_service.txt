Learn how to turn text into speech
in this episode of Azure Tips and Tricks.
You can use the Azure Neural Text to Speech service to
turn text into human speech in many languages and voices.
Let's create a small app to use the service.
To follow along, you need the latest version of Visual Studio,
and you can also do the same in Visual Studio Code.
I'll start by creating a text to speech service in Azure.
Here, let's search for Speech.
Okay, there it is, Create.
This creates a Cognitive Service, Speech Service,
which includes API endpoints like the Text to Speech service.
Let's start by giving it a name.
Next, I'll pick a location,
also a pricing tier,
and now select a Resource group. That's it.
Created and I'll skip to when it is done.
Here it is. This is the Cognitive Services, Speech Service.
Let's take a look at the Keys and Endpoint blade.
Okay, we need this information for our application.
We need the access key and also the location,
West Europe, in my case.
All right, let's use the service in an app.
This is Visual Studio,
and I've already created a simple console application.
The first thing that I changed was to
add a NuGet Package. Let's take a look.
I added this one for the Cognitive Services, Speech Service.
Okay, let's go back to the Program.cs.
In here, I've added a using for
the Cognitive Services Speech namespace
and here I create a new config with
the access key and location that we saw in the portal.
Next, I use this config to create
a speech synthesizer and finally,
I invoke SpeakTextAsync
with a text that I want to be turned into speech.
Let's try this out and there it goes.
>> Synthesizing directly to speaker output.
>> See? The audio comes directly from the default audio device.
Cool. These are the default settings,
which means that the service detects the language of
the text and uses the default voice to synthesize it.
It uses US English for this.
You can change these defaults for instance, by inserting this.
This configures the speech service to use
British English instead. Let's see.
>> Synthesizing directly to speaker output.
>> Yep, that works.
You can use multiple voices for a language,
so I can change this to use another voice. Let's try this one.
>> Synthesizing directly to speaker output.
>> See? That sounds very different. Very cool.
Also, by default, the audio is
returned through the default audio output of your device.
You can change this to return the audio into
a memory stream or into a file like this.
This outputs the audio into a file called
audio.wav and you can tweak
the parameters of the audio that goes into that file as well.
The Azure Neural Text to Speech service
enables you to convert text to life-like speech,
which is close to human parity.
Go and check it out.